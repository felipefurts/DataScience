{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INF-616-1 - Atividade 1: máquina de vetor de suporte e validação cruzada\n",
    "\n",
    "Professor: Ricardo Torres -- rtorres@ic.unicamp.br  \n",
    "Monitor: Lucas David -- lucasolivdavid@gmail.com\n",
    "\n",
    "Este *notebook* faz parte da disciplina INF-616 no curso de extensão MDC.  \n",
    "Demais artefatos podem ser encontrados no moodle da disciplina: \n",
    "[moodle.lab.ic.unicamp.br/317](https://moodle.lab.ic.unicamp.br/moodle/course/view.php?id=317)\n",
    "\n",
    "Instituto de Computação - Unicamp 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1082141)\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo o conjunto de dados smart-debt-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '/C:\\Users\\EMELFEL\\OneDrive - Ericsson AB\\Curso\\Aprendiado de maquina supervisionado 2\\ExercícioAtividade 1/smart-debt-manager.csv'\n",
    "debt = pd.read_csv(dataset, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amostra com os cinco primeiros clientes no conjunto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "debt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descrição geral de características:\n",
    "\n",
    "- OHXACT: id of a specific invoice\n",
    "- CUSTOMER_ID: id of this invoice's customer\n",
    "- OHENTDATE: date, in seconds from 1970, when the invoice was generated\n",
    "- OHDUEDATE: date, in seconds from 1970, when the invoice is due\n",
    "- OHINVAMT_DOC: total value of the invoice, in bangladeshi takas\n",
    "- PAYMENT_DATE*: date, in seconds from 1970, when the invoice was actually paid\n",
    "- PAYMENT_LABEL*: whether the invoice was paid before ('On time'), after ('Late') the due date or not at all ('')\n",
    "- PAYMENT_LABEL2*: whether the invoice was paid before the due date ('On time'), up to 3 days after it ('Grace period'), after that ('Late') o not at all\n",
    "- PAYMENT_COUNT*: number of payments for this invoice\n",
    "- OHINVAMT_DOC_1*: total value value of the paid invoices, in ganbladeshi takas\n",
    "- PAYMENT_AMOUNT*: amount paid by the customer regarding this invoice's period\n",
    "- CSACTIVATED: date, in seconds from 1970, when the customer's account was activated\n",
    "- COSTCENTER_ID: customer's costcenter\n",
    "- TMCODE: customer's rateplan\n",
    "- CSCLIMIT: customer's credit limit\n",
    "- CASHRETOUR*: number of disputes won by the customer\n",
    "- CHARGING_ENGINE_CODE: to which charging engine this invoice belongs to\n",
    "- PAYMENT_METHOD_IND*: payment method used to pay such invoice, if any (bank transfer or direct payment)\n",
    "- TIME_UNTIL_DUEDATE: time, in seconds, between invoice generation and due date\n",
    "- TIME_AS_CUSTOMER: time, in seconds, between customer activation and due date\n",
    "- IS_LATE*: whether the invoice was not paid in time\n",
    "- GRACE_PERIOD*: whether the invoice was paid in the first 3 days after the due date\n",
    "- GRACE_PERIOD2*: whether the invoice was paid in the first 10 days after the due date\n",
    "- TOO_LATE*: whether the invoice was not paid up to 10 days after the due date\n",
    "- MONTH: duedate's month\n",
    "- INV_LAST_YEAR: total number of invoices for this customer in the 12 months prior to this invoice's due date\n",
    "- INV_LAST_YEAR_LATE: total number of invoices for this customer in the 12 months prior to this invoice's due date that were not paid up to the due date\n",
    "- INV_LAST_YEAR_CHARGE: total value of invoices for this customer in the 12 months prior to this invoice's due date\n",
    "- INV_LAST_YEAR_PAID: total value paid by this customer in the 12 months prior to this invoice's due date\n",
    "- INV_LATE_RATIO: proportion of late invoices over total invoices, for this customer, in the last 12 months\n",
    "- INV_PAID_VALUE_RATIO: proportion of absolute total paid value over total charged value, for this customer, in the last 12 months\n",
    "\n",
    "The features marked with an asterisk should only be used as target/validation values and not used for training, since such information wouldn't be available during training for a new invoice.\n",
    "\n",
    "All data was collected from real entries covering a period of 10 years.\n",
    "Most information comes from BSCS tables \"ORDERHDR_ALL\" and \"CUSTOMER_ALL\".\n",
    "Tardiness features (IS_LATE, TOO_LATE etc) were calculated by checking whether a given customer had payments with enough value up to a threshold(0 for IS_LATE, 10 days for GRACE_PERIOD_2 etc) time after the due date of a given invoice.\n",
    "\n",
    "The last 6 features were obtained by aggregating, over 12 months, all past invoices and payments related to a given customer in a giver moment (using, as reference, the due date of the observed invoice)\n",
    "\n",
    "Dates were all transformed to seconds from 1970 in order to help numerical operations. All other data is displayed as it was collected from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifiers = ['OHXACT', 'CUSTOMER_ID', 'COSTCENTER_ID', 'TMCODE', 'CHARGING_ENGINE_CODE']\n",
    "post_payment_vars = ('PAYMENT_DATE PAYMENT_LABEL PAYMENT_LABEL2 PAYMENT_COUNT '\n",
    "                     'OHINVAMT_DOC_1 PAYMENT_AMOUNT CASHRETOUR PAYMENT_METHOD_IND '\n",
    "                     'IS_LATE GRACE_PERIOD GRACE_PERIOD2 TOO_LATE').split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessamento\n",
    "\n",
    "Vamos aplicar algumas operações sobre os dados para facilitar a manipulação adiante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtraímos os códigos 1 e 2 por 1, resultando em 0 e 1.\n",
    "debt['CHARGING_ENGINE_CODE'] -= 1\n",
    "\n",
    "# preenchemos todos os labels '' com 'not-paid' nas colunas de pagamento.\n",
    "debt.fillna({ 'PAYMENT_LABEL': 'Not paid', 'PAYMENT_LABEL2': 'Not paid' }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribuição das características no conjunto\n",
    "\n",
    "Esta visualização permite relacionar cada característica do conjunto par-a-par,\n",
    "onde a figura na posição $(i, j)$ contém a distribuição que a característica $i$ assume em relação à $j$.\n",
    "A diagonal principal é a exceção, mostrando o histogram da variável $i$.\n",
    "\n",
    "Primeiro, definimos todas as variáveis que irão aparecer no nosso gráfico de distribuição:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspecting_vars = ['OHINVAMT_DOC', 'CSCLIMIT', 'TIME_UNTIL_DUEDATE',\n",
    "                   'TIME_AS_CUSTOMER', 'INV_PAID_VALUE_RATIO']\n",
    "\n",
    "features = set(debt.columns) - set(identifiers) - set(post_payment_vars)\n",
    "features.add('CHARGING_ENGINE_CODE')\n",
    "\n",
    "target = 'PAYMENT_LABEL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora selecionamos aleatoriamente um subconjunto, a fim de acelerar o processo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = np.arange(len(debt))\n",
    "np.random.shuffle(selected)\n",
    "selected = selected[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(debt.loc[selected].fillna(0),\n",
    "             hue=target,\n",
    "             diag_kind='hist',\n",
    "             vars=inspecting_vars);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destes gráficos, podemos observar algumas relações interessantes:\n",
    "\n",
    "- A grande maioria das amostras apresenta um limite de crédito inferior ou igual à 1000\n",
    "- As poucas amostras com alto `INV_PAID_VALUE_RATIO` vêm principalmente de novos e médio clientes\n",
    "- Clientes novos parecem compor uma maior taxa de amostras `not-paid`\n",
    "\n",
    "Um jeito mais certo enxuto é observar a **correlação absoluta** entre as variáveis do conjunto, que descrevem as relações lineares absolutas entre os pares de variáveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlations = debt.loc[selected, features].corr().abs()\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "ax = sns.heatmap(correlations, linewidths=.5, cmap='YlGnBu',\n",
    "                 annot=True, fmt='.2f',\n",
    "                 xticklabels=features, yticklabels=features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "plt.title('Frequencia das classes em todo o conjunto (%i amostras)' % len(debt))\n",
    "labels, counts = np.unique(debt.loc[selected, target], return_counts=True)\n",
    "sns.barplot(labels, counts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelando o problema\n",
    "\n",
    "Vamos definir o modelo que é alimentado por todas as variáveis pré-pagamento (ao qual temos acesso) que não são identificadores (específicos de um indivíduo ou característica categórica). A exceção é *CHARGING_ENGINE_CODE*, que se mantém por se tratar de um valor binário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Features utilizadas:', *features, sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restringindo o problema em duas classes\n",
    "A informação alvo a ser predita é `PAYMENT_LABEL`. Como só vimos o SVC binário até agora, vamos binarizar o problema combinando as classes \"Late\" e \"not-paid\". Isso irá re-organizar nosso conjunto em duas classes: \"on time\" e \"not on time\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = debt[features]\n",
    "y = debt[target].copy()\n",
    "\n",
    "y[y == 'Late'] = 'Not on time'\n",
    "y[y == 'Not paid'] = 'Not on time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "plt.title('Frequencia das classes em todo o conjunto (%i amostras)' % len(debt))\n",
    "labels, counts = np.unique(y, return_counts=True)\n",
    "sns.barplot(labels, counts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos metade dos dados para testar nosso estimador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = .5\n",
    "train_samples = ceil((1 - test_size) * len(debt))\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,\n",
    "                                                    y,\n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=8173)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A média e desvio padrão de cada característica é calculada. As amostras são então normalizadas a fim de remover translação e garantir um espalhamento similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "encoder = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    StandardScaler())\n",
    "\n",
    "z_train = encoder.fit_transform(x_train)\n",
    "z_test = encoder.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando os dados\n",
    "\n",
    "Uma outra forma de visualizar conjuntos é rotacioná-los até que as direções que maximizam a variabilidade\n",
    "dos dados (as componentes principais) estejam alinhadas com a base canônica $\\{x, y, z\\}$.  \n",
    "Isso faz mais sentido sobre um espaço de características métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "encoder2D = TSNE(n_components=2)\n",
    "w_train = encoder2D.fit_transform(z_train[:1000])\n",
    "w_test = encoder2D.fit_transform(z_test[:1000])\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(121)\n",
    "sns.scatterplot(*w_train.T, hue=y_train[:1000]).set_title('Train dataset')\n",
    "plt.subplot(122)\n",
    "sns.scatterplot(*w_test.T, hue=y_test[:1000]).set_title('Test dataset');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: como esperado, as amostras selecionadas para compor o conjunto de teste parecem estar suficientemente espalhadas,\n",
    "para o propósito do nosso pequeno exercício. Além disso, as proporções de rótulos presentes em treinamento e teste não estão muito distantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelando um detector de pagamentos\n",
    "\n",
    "**Execício (2 pts):** instancie uma máquina de vetor de suporte binário **linear** e a treine sobre o conjunto de dados de treino preprocessado `(z_train, y_train)`.\n",
    "\n",
    "Leia mais sobre as máquinas de vetor de suporte implementadas no sklearn na página de documentação do módulo [scikit-learn.org/svm](https://scikit-learn.org/stable/modules/svm.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn... import ...\n",
    "# model = ...\n",
    "# model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do modelo treinado\n",
    "\n",
    "Para verificar a capacidade de generalização do modelo,\n",
    "devemos avaliar seu desempenho sobre o conjunto de teste previamente separado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svm.predict(z_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício (1 pts):** descreva o número total de acertos, a acurácia e a matriz de confusão.  \n",
    "Não utilize loops! Somente operações vetoriais ou utilitários no sklearn (dica: [sklearn/metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits = ...\n",
    "# acc = ...\n",
    "# cm = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um destes utilitários é muito útil: o `classification_report`.  \n",
    "Ele condensa algumas métricas populares em um único relatório:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = svm.predict(z_test)\n",
    "report = metrics.classification_report(y_test, labels)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perguntas (1 pts):**\n",
    "\n",
    "- O modelo prediz todas as classes com alta acurácia?\n",
    "- O modelo se comporta de forma similar em teste?\n",
    "\n",
    "R:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelando um detector de pagamentos no período correto e atrasados\n",
    "\n",
    "**Exercício (1 pt):** altere o conjunto para unir as amostras `Paid` e `Late` em uma único rótulo `Paid`. O conjunto deve ser binarizado sob os rótulos `Paid` e `Not paid`. Re-treine um classificador baseado em máquina de vetor de suporte sobre esse conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = debt[features]\n",
    "y = debt[target].copy()\n",
    "\n",
    "# Modifique os rótulos em `y`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa os conjuntos de treino/teste.\n",
    "test_size = .5\n",
    "train_samples = ceil((1 - test_size) * len(debt))\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=8173)\n",
    "\n",
    "# Trata valores faltantes e normaliza os dados originais.\n",
    "z_train = encoder.fit_transform(x_train)\n",
    "z_test = encoder.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm = ...\n",
    "# svm.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício (1 pts):** avalie o seu SVM sobre o conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_predictions = ...\n",
    "# test_accuracy = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confiança nas predições\n",
    "\n",
    "As máquinas de vetor de suporte trabalham com o conceito de distância ao hiperplano,\n",
    "em vez da probabilidade usual gerada pela função logística. Nessa configuração, amostras próximas ao hiperplano apresentam uma maior similaridade com as classes vizinhas do que amostras distantes a ele.\n",
    "\n",
    "Podemos exibir a distribuição de distâncias em treino e teste da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "for index, (tag, z) in enumerate((('train', z_train),\n",
    "                                  ('test', z_test))):\n",
    "    plt.subplot(1,2, index + 1)\n",
    "    plt.title('Distribuição de confiança sobre o conjunto de %s' % tag)\n",
    "\n",
    "    distance = svm.decision_function(np.clip(z, -2, 2))\n",
    "    sns.distplot(distance, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta (1 pts):** considerando a distribuição de confiança sobre treino e teste, o modelo apresenta maior dificuldade para testar amostras no conjunto de teste do que no de treino?\n",
    "\n",
    "R:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando múltiplos estimadores sobre um conjunto de dados\n",
    "\n",
    "A fim de manter uma melhor representatividade de todo o conjunto, podemos empregar a técnica de validação cruzada para testar dois ou mais classificadores e verificar qual apresenta melhor comportamento sobre o conjunto de dados.\n",
    "\n",
    "**Atividade (2 pts):** instancie dois ou mais classificadores binários e utilize o procedimento de validação-cruzada sobre os dados de treino. Registre o resultado do processo para cada estimador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "# from sklearn... import ...Classifier\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, random_state=7129)\n",
    "\n",
    "# estimators = [e1, e2, ...]\n",
    "# results = [... for e in estimators]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade (1 pt):** selecione o estimador que apresenta maior pontuação média sobre as *folds* de validação. Treine-o sobre todo o conjunto de treino e avalie sua performance sobre o conjunto de teste.\n",
    "\n",
    "Importante: como tomamos uma decisão considerando os dados usados na validação cruzada (qual estimador utilizar), **não devemos unir** os dados de teste com os de treinamento antes do processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_ix = ...\n",
    "# e = estimators[best_ix]\n",
    "# treine `e`...\n",
    "# avalie `e`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta (1 pt):** este estimador apresenta maior acurácia, comparada à máquina de vetor de suporte treinada anteriormente?\n",
    "\n",
    "R: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
