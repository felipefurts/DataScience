{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF-616 - Exercício 2 - Aula 3/4: *support vector machines*\n",
    "\n",
    "Professor: Ricardo da Silva Torres -- rtorres@ic.unicamp.br\n",
    "\n",
    "Professor: Alexandre Ferreira -- melloferreira@ic.unicamp.br  \n",
    "\n",
    "Monitor: Lucas David -- lucasolivdavid@gmail.com\n",
    "\n",
    "Este *notebook* faz parte da disciplina INF-616 no curso de extensão MDC.  \n",
    "Demais artefatos podem ser encontrados no moodle da disciplina: \n",
    "[moodle.lab.ic.unicamp.br/332](https://moodle.lab.ic.unicamp.br/moodle/course/view.php?id=332)\n",
    "\n",
    "Instituto de Computação - Unicamp 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1082141)\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificando imagens de dígitos\n",
    "### Lendo o conjunto de dados\n",
    "\n",
    "**Pen-Based Recognition of Handwritten Digits Data Set**\n",
    "é um banco de imagens simples e bem conhecido em reconhecimento de imagens.  \n",
    "Ele é composto por imagens em escala cinza de 8 por 8 pixels divididas em 10 classes de dígitos.\n",
    "\n",
    "Uma descrição completa pode ser encontrada no seguinte link: [archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits](http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = datasets.load_digits(return_X_y=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                                    test_size=.5)\n",
    "print('samples in train: %i' % x_train.shape[0],\n",
    "      'samples in test: %i' % x_test.shape[0],\n",
    "      'features: %i' % x_train.shape[1],\n",
    "      'classes: %i' % (np.max(y_train) + 1),\n",
    "      sep='\\n', end='\\n\\n')\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 64 primeiras amostras no conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "for ix in range(8  * 32):\n",
    "    plt.subplot(8, 32, ix + 1)\n",
    "    plt.imshow(x_train[ix].reshape(8, 8), cmap='Greys')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando o conjunto e frequências das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "encoder2D = TSNE()\n",
    "w_train = encoder2D.fit_transform(x_train)\n",
    "w_test = encoder2D.fit_transform(x_test)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "categorical_colors = sns.color_palette()\n",
    "\n",
    "for ix, (x, y) in enumerate(((w_train, y_train), (w_test, y_test))):\n",
    "    plt.subplot(1, 2, ix + 1)\n",
    "    sns.scatterplot(*x.T, hue=y, palette=categorical_colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Frequencia das classes no conjunto de treinamento (%i amostras)' % len(x_train))\n",
    "labels, counts = np.unique(y_train, return_counts=True)\n",
    "sns.barplot(labels, counts)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Frequencia das classes no conjunto de teste (%i amostras)' % len(x_test))\n",
    "labels, counts = np.unique(y_test, return_counts=True)\n",
    "sns.barplot(labels, counts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelando um classificador de digitos\n",
    "\n",
    "**Atividade (3 pts):** defina e treine uma máquina de vetor de suporte com kernel RBF, utilizando o scikit-learn.  \n",
    "Lembre-se que este estimador é extremamente sensível à dados desnormalizados,\n",
    "o que torna o pre-processamento um passo indispensável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predictions = sv.predict(x_test)\n",
    "probabilities = sv.decision_function(x_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em problemas envolvendo muitas classes, simplesmente exibir a matriz de confusão\n",
    "com a função `print` gera uma representação difícil de ler.  \n",
    "Veja este exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós podemos melhorar este efeito utilizando um `heatmap`,\n",
    "onde a grandeza dos valores se torna diretamente proporcional à intensidade da cor adjacente.\n",
    "\n",
    "**Atividade (1 pt):** calcule a matriz de confusão relativa $R$, que guarda porcentagens de incidências em vez das contagens absolutas. Finalmente, utilize o `heatmap` do seaborn para exibir a matriz alcançada.\n",
    "\n",
    "\n",
    "Dica: seja $C = \\{c_{ij}\\}_{10\\times 10}$ a matrix de confusão original, $R = \\{r_{ij} | r_{ij} := \\frac{c_{ij}}{\\sum_k c_{ik} }\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = metrics.confusion_matrix(y_test, predictions)\n",
    "# r = ...\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.heatmap(r, linewidths=.5, cmap='YlGnBu', annot=True, fmt='.1%');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta (1 pt):** quais dígitos são confundidos com maior frequência no conjunto de teste?\n",
    "\n",
    "R:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Regressors\n",
    "\n",
    "O conjunto *Doctor feeds prediction* contém uma relação entre um conjunto de características associadas à um médico atendente e o preço da consulta cobrada. O objetivo é **regredir** este valor o mais próximo possível do valor esperado.   \n",
    "Ele pode ser encontrado no seguinte link: [kaggle.com/nitin194/doctor-fees-prediction](https://www.kaggle.com/nitin194/doctor-fees-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = (pd.read_csv(f'../datasets/doctor-fees/{stage}.csv')\n",
    "               for stage in ('train', 'test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processamento dos dados para um formato mais limpo\n",
    "\n",
    "- Remove uma linha inválida, contendo `\"years experience\"` como valor para a coluna qualificação\n",
    "- Preenche todos os `Place` e `Profile` com valor igual à `NaN` com a tag `unknown`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(frame):\n",
    "    frame['Rating'] = frame['Rating'].str.replace('%', '').astype(float) / 100.0\n",
    "    frame['Experience'] = frame['Experience'].str.replace('years experience', '').astype(float)\n",
    "    frame['Qualification'] = frame['Qualification'].str.replace('[^a-zA-Z]', ' ').str.lower()\n",
    "    frame['Place'] = frame['Place'].str.replace('[^a-zA-Z]', ' ').str.lower()\n",
    "\n",
    "preprocess(train)\n",
    "preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_row = train['Qualification'].str.contains('years experience')\n",
    "train = train[~invalid_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna({'Place': 'unknown', 'Profile': 'unknown'}, inplace=True);\n",
    "test.fillna({'Place': 'unknown', 'Profile': 'unknown'}, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exibindo frequência com que as qualificações, locais e perfis ocorrem nos conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_freq(frame, feature, showing=30):\n",
    "    labels, counts = np.unique(frame[feature].dropna(), return_counts=True)\n",
    "\n",
    "    # ordena pelas mais frequentes\n",
    "    p = np.argsort(counts)[::-1]\n",
    "    labels, counts = labels[p], counts[p]\n",
    "\n",
    "    g = sns.barplot(labels[:showing], counts[:showing])\n",
    "    g.set_xticklabels(labels[:showing], rotation=90)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_feature_freq(train, 'Qualification')\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_feature_freq(test, 'Qualification')\n",
    "\n",
    "qualifications, counts = np.unique(train['Qualification'].dropna(), return_counts=True)\n",
    "p = np.argsort(counts)[::-1]\n",
    "qualifications = qualifications[p];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_feature_freq(train, 'Place')\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_feature_freq(test, 'Place')\n",
    "\n",
    "places, counts = np.unique(train['Place'].dropna(), return_counts=True)\n",
    "p = np.argsort(counts)[::-1]\n",
    "places = places[p];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_feature_freq(train, 'Profile')\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_feature_freq(test, 'Profile');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelando um regressor de custo de consulta\n",
    "\n",
    "Vamos codificar as características categóricas usando o one-hot encoding.  \n",
    "Entretanto, dado o alto número de ocorrências únicas, nós consideramos somente os 200 valores de maior frequência.\n",
    "\n",
    "As características contínuas são simplesmente normalizadas com o `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "retained_qualif = qualifications[:200].tolist()\n",
    "retained_places = places[:200].tolist()\n",
    "\n",
    "qualif_places_enc = OneHotEncoder(categories=[retained_qualif, retained_places], handle_unknown='ignore')\n",
    "profile_enc = OneHotEncoder()\n",
    "continuous_enc = make_pipeline(SimpleImputer(strategy='median'),\n",
    "                               StandardScaler())\n",
    "\n",
    "encoder = ColumnTransformer([\n",
    "  ('q_pla', qualif_places_enc, ['Qualification', 'Place']),\n",
    "  ('prof', profile_enc, ['Profile']),\n",
    "  ('ex_ra', continuous_enc, ['Experience', 'Rating'])\n",
    "])\n",
    "\n",
    "train_e = encoder.fit_transform(train)\n",
    "test_e = encoder.transform(test)\n",
    "\n",
    "fee_enc = StandardScaler()\n",
    "ye_train = fee_enc.fit_transform(train[['Fees']].astype(float)).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade (4 pts):** treine dois ou mais regressores --- onde ao menos um é baseado em *máquina de vetor de suporte* --- e reporte o seus respectivos erros quadráticos médios (MSE) sobre as porções de validação separadas. Respeite as seguintes regras:\n",
    "\n",
    "- Utilize a estratégia 5-3 para fazer a validação cruzada dos resultados e buscar hiperparâmetros\n",
    "- Busque ao menos dois parâmetros em cada regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "# from sklearn... import ...Regressor\n",
    "\n",
    "# model = ...\n",
    "# params = ...\n",
    "# grid = GridSearchCV(model, params)\n",
    "# results = cross_validate(...)\n",
    "#\n",
    "# model_2 = ...\n",
    "# params = ...\n",
    "# grid_2 = GridSearchCV(model, params)\n",
    "# results_2 = cross_validate(...)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta (1pt):** que estimador apresentou os melhores resultados?\n",
    "\n",
    "R:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
